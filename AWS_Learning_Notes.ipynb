{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=index></a>\n",
    "# Index\n",
    "- <a href=#s3>S3</a>\n",
    "- <a href=#cloudfront>CloudFront</a>\n",
    "- <a href=#ec2>EC2</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=s3></a>\n",
    "## S3\n",
    "<a href=#index>Go to Index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic info\n",
    "- Object based storage (not block storage)\n",
    "- ACL are used to control access to specific resources. Bucket policy applies to the whole bucket.\n",
    "- When a file is uploaded to S3, the browser gets a 200 response for a successful upload. \n",
    "- All objects are private by default\n",
    "- Min sized object on S3 is 0 bytes (eg: Delete marker)\n",
    "- 3 types of storage - Standard, IA (Infrequently accessed), Reduced Redundancy Storage\n",
    "- Can use client side or server side encryption. Server side encryption consists of 3 options -\n",
    "\t- S3 (SSE-S3)\n",
    "\t- KMS (SSE-KMS)\n",
    "\t- Customer provided keys (SSE-C)\n",
    "- S3 Standard: 11 9s of durability and 4 9s of availability and can stand the loss of two facilities concurrently\n",
    "- S3 IA: Data that is infrequently retrieved but needs to be accessible quickly when needed. Cheaper than Standard but charged per retrieval\n",
    "- 'S3 One Zone - Infrequently Accessed' is replacing Reduced Redundancy Storage (RRS)\n",
    "    - For data that need not be stored in multiple AZ and is infrequently accessed\n",
    "    - Availability is 99.5%\n",
    "- Glacier: Is for data archival. 3 types of retrieval (decreasing order of cost, increasing order of time)\n",
    "    - Expedited\n",
    "    - Standard\n",
    "    - Bulk\n",
    "- S3 buckets can be configured to create access logs (can dump all logs to another bucket)\n",
    "- S3 uploads can get much faster if done as multi-part upload\n",
    "- Can have upto 100 buckets per account by default\n",
    "- Single operation upload to S3 works for files <5GB. Multi-part works for files from 5MB to 5TB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency\n",
    "- Read after Write consistency for new object PUTS (instantaneous)\n",
    "- Eventual consistency for overwrite PUTS and DELETE actions (can take a little time to propagate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versioning\n",
    "- For a public file with versioning enabled, it will be made private in the new version. \n",
    "- Versioning cannot be removed (can be suspended)\n",
    "- Actually when you delete a file, it gets another version called 'delete marker'. If you delete the delete marker, the file gets restored.\n",
    "\n",
    "- The files only get removed when you got to versioning and remove the versions themselves\n",
    "- There is also an option to enable MFA for deleting files with versioning enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Region Replication (CRR)\n",
    "- When CRR is newly introduced on a bucket, the existing objects are not automatically copied. New and updated objects are copied to the replication bucket. AWS CLI (s3 cp --recursive) can be used to copy all files from the primary to the replication bucket\n",
    "- Versioning must be enabled (source and target) for CRR\n",
    "- Src and target should be in different regions (Cross **Region** replication)\n",
    "- At this time, you cannot do replication to multiple buckets (daisy chaining is not supported at present)\n",
    "- Deleting files (delete marker) or deletion of individual versions are not replicated to the secondary buckets (this is an AWS security feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle rule\n",
    "- Main idea is to reduce cost\n",
    "- S3 can automatically move contents of a bucket (or folder or things with a spefied tags ) to S3-IA and later to S3 Glacier based on what we set in the Management>Lifecycle tab added as Lifecycle rule. - Can also be configured to permanently delete stuff at some point\n",
    "- To move to S3-IA requires a minimum of 30 days after creation and moving to Glacier requires 30 days after residing in IA or 60 days from creation\n",
    "- Can be done along with versioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Security & Encryption\n",
    "- By default all S3 objects are private\n",
    "- Use SSL/TLS (https) for encryption during transit\n",
    "- At rest use one of three server side encryption options \n",
    "    - S3 Managed Keys (SSE-S3)\n",
    "    - S3 KMS (charges you, tells you who is decrypting what when)\n",
    "    - Customer provided key (SSE-C). You handle the keys\n",
    "- Can also choose to do client side encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Gateway\n",
    "Is a service that connects local on-prem IT network with a cloud storage for scalable and cost-effective storage. It can connect to the on-prem storage and automatically replicate things on to S3 or S3 Glacier.\n",
    "\n",
    "There are 4 types of storage gateways -\n",
    "1. File Gateway (NFS) - for media files, flat files, etc.. stored directly on S3\n",
    "2. Volume Gateways (iSCSI):  for block based storage. Think of these as a connection to harddisks(disk **volumes**). Data written to these disk volumes can be backed up using EBS. These can be used to save system snapshots. These snapshots are incremental (only changes get captured). Snapshot storage is also compressed to minimize storage costs.\n",
    "    - Stored Volumes: Entire dataset is stored on site and is asynchronously backed up to S3\n",
    "    - Cached Volumes: Entire data is stored on S3 and most frequently accessed data is cached on site\n",
    "3. Virtual Tape Library Gateway (VTL): Used for backup. Uses popular applications like NetBackup, Backup exec, Veenam etc.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snowball\n",
    "\n",
    "Legacy option was Import/Export Disk (portable disks) that Amazon allowed for large scale data transfer. \n",
    "\n",
    "Snowball can import to and export from **S3**.\n",
    "- Snowball: 256 AES encryption, tamper proof, multiple layer security, trusted platform module. comes with a kindle to track the device. Software erase after each transfer (so that no one can retrieve data from it)\n",
    "- Snowball Edge: like Snowball, but also has compute capacity. Eg: Airline manufacturer can place this device in a test flight plane for data capture. Like an mobile AWS datacenter in a box.\n",
    "- Snowmobile: Petabytes or exabytes of data. Truck trailer. Even a complete datacenter migration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Transfer Acceleration\n",
    "Instead of uploading drectly to an S3 bucket in some region directly, upload to an edge location that is close to you.\n",
    "\n",
    "Within S3 Properties>Transfer acceleration. Provides a new endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Static Website Hosting\n",
    "- The public endpoing follows a specific format \"<bucket-name>-s3-website-<region>-amazonaws.com\"\n",
    "- Use bucket policy to make entire S3 bucket public\n",
    "- S3 scales automatically to meet demand for the website\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=cloudfront></a>\n",
    "## CloudFront\n",
    "<a href=#index>Go to Index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic\n",
    "- CDN - Content Delivery Network. Something that enables faster content delivery of content if the geographical location of the requestor and requested content might otherwise cause delay in service.\n",
    "- Edge location (EL) is different from AWS region or AZ. Currently there are over 50 ELs. \n",
    "- Edge location takes content from origin. At this time origin can be \n",
    "\t- S3 bucket\n",
    "\t- EC2 instance\n",
    "\t- Elastic Load Balancer\n",
    "\t- Route53\n",
    "\t- Can also be an external source of the files\n",
    "- Distribution is the name given to the CDN which consists of a collection of Edge locations\n",
    "- When content is requested first time, it is fetched from origin and then cached in the EL. This is cached for a specified TTL (Time To Live)\n",
    "- There are two types of distribution\n",
    "\t- Web Distribution - Typically used for websites\n",
    "\t- RTMP - used for media streaming\n",
    "- Edge locations are **not read-only**. They can also be used for put operations and that object will then be written back to the origin.\n",
    "- You can clear the cached objects but you will be charged for it. The normal behavior is that the cached object will expire on its own after the specified TTL.\n",
    "- Specifics of setting up the CloudFront Distribution\n",
    "    - CloudFront uses an identity to access the S3 bucket (Origin Access Identity parameter in the CloudFront dist setup)\n",
    "    - In the setup, remember to 'Grant Read permissions on bucket' to 'yes'\n",
    "    - Allow HTTP and HTTPS(recommended for regular pages)\n",
    "    - TTL is an important design consideration (set based on how frequently the objects change)\n",
    "    - Pick the default SSL certificate so as to support HTTPS unless you can publish a certificate\n",
    "    - There is a feature called Restrictions - allows Geo-Restrictions using a Whitelist and a Blacklist. Blacklist allows global access and restricts to few entities. Whitelist only serves to the entities in the whitelist.\n",
    "    - \"Invalidation\" is the process of removing an object that is cached on CloudFront. Remember that this is to delete objects before TTL. *This costs money.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ec2\">\n",
    "# EC2: Elastic Cloud Compute\n",
    "<a href=\"#index\">Back to Index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provides resizeable compute capacity in the cloud: \n",
    "    - can scale up and down (increase/decrese capacity by starting new instances in minutes)\n",
    "    - can scale out (Elastic load balancer)\n",
    "    \n",
    "EC2 can be provisioned -\n",
    "- On Demand: \n",
    "    - Pay fixed rate by the hour - Windows (or by the second - Linux)\n",
    "    - Good for temporary needs (Dev)\n",
    "- Reserved instances: \n",
    "    - Contracts with Amazon 1 or 3 year contracts. Significant dicount (75% off of on-demand prices)\n",
    "    - Great for predictible usage\n",
    "        - Standard RIs (upto 70% off on-demand)\n",
    "        - Convertible RIs (upto 54% off on-demand) allow you to change the attributes of the RIs as long as it creates instances of equal or higher value\n",
    "        - Scheduled RIs: good for a known pattern in demand/requests.\n",
    "- Spot Instances: \n",
    "    - By at a price that you are comfortable with (like a market)\n",
    "    - Flexible start and end price\n",
    "    - Applications that are only feasible at low compute prices\n",
    "    - If Spot instance is terminated by Amazon EC2, you will not be charged for a partial hour of usage. However, if you terminate the instance yourself, you will be charged for the complete hour in which the instance ran.\n",
    "- Dedicated Hosts: \n",
    "    - A physical machine for you. Eg: If your license is attached to a mac id, you can use it on cloud by hosting it in a Dedicated host. \n",
    "    - It could be because of regulatory requirements too\n",
    "    - Can be purchased on-demand and can also be reserved (upto 70% off on-demand price)\n",
    "\n",
    "Pneumonic to remember all instance types: FIGHT DR.Mc PX. There are instances that star with all these letters. Think Edward Norton fights (Fight) Dr. McDonald (Dr.Mc) who is from Scotland and hands out pictures (PX) of Scotlant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBS\n",
    "Elastic Block Storage. If EC2 are servers online, EBS are disks online. EBS is placed in a specific AZ and replicated within that AZ.\n",
    "Comes in different kinds - \n",
    "    - General purpose SSD (GP2): \n",
    "        - balances price and performance\n",
    "        - speed of 3 to 10k IOPS per GB. And the ability to burst upto 3000 IOPS for extended periods of time for volumes 3334 GB and above\n",
    "   - Provisioned SSD IOPS:\n",
    "       - For I/O intensive applications like large relational or NoSQL databases\n",
    "       - if you need more than 10,000 IOPS\n",
    "       - Can provision up to 20,000 IOPS\n",
    "   - Throughput Optimized HDD (ST1) (magnetic disk):\n",
    "       - Cannot be boot volume. Can only be additional volumes (eg: cannot be C drive in Windows)\n",
    "       - Good for big data, data warehousing, log processing etc\n",
    "   - Cold HDD (SC1) (magnetic disk)\n",
    "       - Lowest cost for infrequently accessed workloads\n",
    "       - File server\n",
    "       - Cannot be boot volume\n",
    "   - Magnetic (Standard) (legacy):\n",
    "       - Lowest cost per GB of all EBS bootable vol types\n",
    "       - Ideal for worlkoads where data is accessed infrequently\n",
    "       - For applications where the lowest storage cost is important\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EC2 Hands-on session\n",
    "- Tenancy is the property that enables you to use a dedicated host or a shared host\n",
    "- Remember that one Subnet (within a VPC) falls in one AZ\n",
    "- Monitoring property during EC2 allows for detailed monitoring (RAM, CPU utilzation etc. every 1 min). Default is to track these every 5 mins\n",
    "- Delete on Termination is the default behavior for EBS volumens attached to EC2 instances\n",
    "- There are two checks that are listed on EC2 console\n",
    "    - System status check: Ensures network connectivity to the instance is working fine. This is equivalent to checking that the Hypervisor level things are working alright\n",
    "    - Instance status check: Ensures the OS is able to receive packages \n",
    "    \n",
    "- By default, the root volume cannot be encrypted. It can be encrypted by creating a copy and encrypting it and being used as root volume.\n",
    "- Termination protection is turned off by default\n",
    "- On EBS backed instance, the default action is for the root EBS volume to be deleted when instance is terminated\n",
    "- EBS root volumes of your default AMIs cannot be encrypted. Can use a third party tool such as bit locker to encrypt root volumes. \n",
    "- Additional EBS volumes can be encrypted\n",
    "- Terminated instances will be visible in the list of instances for 1 hour after termination\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Security Groups\n",
    "- Any change that is made to an SG takes effect immediately\n",
    "- SGs are STATEFUL (in contrast with a Network Access Control list). Meaning if you allow inbound rules, then those will also receive outbound traffic even if there are no rules mentioned in the outbound section of the SG.\n",
    "- You cannot deny access of specific kind or for a specific IP address using SGs. You can only 'allow' using SGs. There are no inbound rules by default\n",
    "- All outbound traffic is allowed by default\n",
    "- Can attach multiple SGs to an instance\n",
    "- Can have any number of EC2 instances within an SG\n",
    "\n",
    "### EBS volumes\n",
    "- EBS volumes have to be in the same AZ as the EC2 instance\n",
    "- To make a copy of EBS in a different AZ, make a snapshot and create volume in required AZ using snapshot\n",
    "- Use the Actions>Copy option to create the instance in another Region\n",
    "- Except 'Standard' (primitive magnetic), all other volumes type and sizes can be edited after creation. No associated downtime\n",
    "- EBS Snapshots are created for backups and EBS images are used to clone EC2 instances\n",
    "- Root volume is deleted when EC2 instance is terminated. Other EBS volumes are not terminated\n",
    "- Can take snapshots when instance is running except if you're taking snapshots of EBS volumes that serve as root volumes\n",
    "- Snapshot of encrypted volumes are encrypted. Volumes restored from encrypted snapshots are encrypted. \n",
    "- Only snapshots of unencrypted snapshots can be shared publicly\n",
    "\n",
    "Volumes exist on EBS. Snapshots exist on S3. Snapshots are incremental (only changes from last snapshot are captured)\n",
    "\n",
    "### AMI \n",
    "AMI is selected based on \n",
    "- Region\n",
    "- OS\n",
    "- Architecture\n",
    "- Launch Permissions\n",
    "- Storage for the Root Device\n",
    "- Storage for Root Device - Instance Store (Ephemeral Storage) or EBS backed volumes\n",
    "    - Remember that instance store cannot have 'start'/'stop' but EBS backed has these. When they are started after being stopped, it starts in a different hypervisor\n",
    "    - Instance store backed instances will lose data if the underlying host fails\n",
    "    - EBS volumes can be detached from one instance and attached to another. This cannot be done for Instance based volumes\n",
    "    - Both types can be rebooted without loss of data\n",
    "    \n",
    "### Elastic Load Balancer\n",
    "Come in 3 types - \n",
    "- Application load balancer: Very advanced, can send specific request to specific web servers, work at layer 7 of TCP model\n",
    "- Network load balancer: For extreme performance, works at connection layer (layer 4). Can handle millions of requests per sec with ultra low latency\n",
    "- Classic load balancer: These are legacy load balancers (what are meant when Elastic Load Balancer is mentioned). Can balance HTTP/HTTPS requests and also use layer-7 specific features (X-forwarded-For and sticky sessions). Can also use strict layer 4 LB for applications that rely strictly on TCP protocol. \n",
    "\n",
    "X-Forwarded-For header can be used to pass the public ip (IPv4) of the requester to the EC2 instance from the ELB\n",
    "\n",
    "If the application stops responding ELB responds with Error code 504 (Gateway Timed Out). Could be because the Web Server or the Database Server failed\n",
    "\n",
    "ELBs do healthchecks for EC2 instances and keeps track of \"InService\" or \"OutOfService\"\n",
    "\n",
    "### Cloudwatch\n",
    "Can be used to monitor components and also set alarms to notify about events of interest\n",
    "- Standard monitoring: 5 mins\n",
    "- Detailed monitoring: 1 mins\n",
    "\n",
    "**Remember that Cloudwatch is for monitoring and CloudTrail is for audit. CloudTrail captures everything that happens within the AWS account**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EC2 bash script (on startup)**\n",
    " - If aws s3 command is used for buckets and EC2 is separate regions, specify the --region parameter with the region of the EC2 instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EC2 Instance Metadata**\n",
    "- Can get instance metadata at http://169.254.169.254/latest/meta-data/ once a user ssh's into the EC2 instance. Use curl command to get response\n",
    "- curl http://169.254.169.254/latest/user-data/ to get the bash script provided to the EC2 instance (it is called user-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto Scaling Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Needs a Launch configuration that runs when new EC2 instances are created\n",
    "- Can choose to increase/decrease instances based on criteria set by user\n",
    "- If a set number of instances are chosen, it creates instances when some of them goes down\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placement Groups (PG)\n",
    "- Name of the PG must be unique within an AWS a/c\n",
    "- Only certain types of instances can be launched in PGs (Compute Optimized, GPU, Memory Optimized, Storage Optimized). \n",
    "- AWS recommends homogeneous instances within placement groups\n",
    "- Cannot merge PGs\n",
    "- Cannot move an existing instance into a PG\n",
    "- Two types - \n",
    "    - Clustered Placement Group (is the older and default one): **All instances are in a single AZ.** When low-network latency is necessary. Eg: if you want to manually set up Hadoop cluster. \n",
    "    - Spread Placement Group: For a group of instances that are placed in distinct underlying hardware. Good for cases where a small number of critical instances are to be kept separate from each other. Good to keep instances in multiple AZs (kind of the opposite of Clustered PG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic File Storage\n",
    "- Block based storage\n",
    "- File storage service for EC2\n",
    "- Storage capacity is elastic, increases and decreases based on more files being added or deleted\n",
    "- Supports NFS v4 protocol (Network File System version 4)\n",
    "- No pre-provisioning required, only pay for the storage you use (30 cents per GB)\n",
    "- Can scale to Petabytes\n",
    "- Can support 100s of concurrent NFS connections\n",
    "- Data is stored across multiple AZ's within a region\n",
    "- Read after write consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda\n",
    "- Automatically scales out\n",
    "- Function invocations are independent (1 event = 1 function invocation)\n",
    "- No servers!\n",
    "- Super cheap!\n",
    "- Example, Amazon Alexa is powered entirely by Lambda functions\n",
    "- Function should end within 5 mins\n",
    "- Triggers\n",
    "    - API Gateway\n",
    "    - S3\n",
    "    - SNS\n",
    "    - Kinesis\n",
    "    - DynamoDB\n",
    "    - AWS IoT\n",
    "    - Alexa Skills Kit\n",
    "    - Alexa Smart Home\n",
    "- Languages\n",
    "    - .net (C#/Powershell)\n",
    "    - Go\n",
    "    - Java\n",
    "    - Python (2 & 3)\n",
    "    - Ruby\n",
    "    - Custom runtime\n",
    "- Billing\n",
    "    - Number of requests\n",
    "    - First 1 million reqs are free; \\$0.2 per 1 million requests \n",
    "    - Duration of code execution rounded up to 100th mS. \n",
    "    - Price depends on amt of memory used too. $0.00001667 per GB-second used\n",
    "    \n",
    "- AWS X-Ray can be used to debug if multiple components are connected and something goes wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read up on\n",
    "- Kubernitics for setting up Docker container EC2 cluster\n",
    "- RAID for backup of EC2 storage devices\n",
    "- EC2 hypervisors\n",
    "    - Nitro\n",
    "    - Xen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNS\n",
    "- Route 53 was named for the highway that goes across US and because DNS is on port 53\n",
    "- Top level domains are controlled by Internet Assigned Numbers Authority (IANA)\n",
    "- Registrars are entities that have permission to allot domain names that map directly to top level domain names eg: Amazon, GoDaddy etc.\n",
    "- The domain names alloted by registrars are registered with InterNIC, a service of ICANN. Each domain name becomes registered in a central database known as the WhoIS database\n",
    "- NS record is Name Server records. Used by top level Domain servers to direct traffic to the Content DNS server which contains the authoritative DNS records\n",
    "- Start of Authority Record (SOA)\n",
    "    - name of server that supplied the data for the zone\n",
    "    - The administrator of the zone\n",
    "    - The current version of the data file\n",
    "    - Default number of seconds for the time-to-live file on resource records\n",
    "- \"A\" Record is a fundamental DNS record to translate a domain name to an ip address\n",
    "- CName (Canonical Name) can be used to resolve one domain name to another\n",
    "- Alias Records is very much like CName in that it is used to map one domain name to another. \n",
    "    - Difference between CName and Alias Records is that Alias records can handle Naked domain names and CName cannot\n",
    "    - Naked domain names are ones without 'www' preceding the domain name. eg: http://acloud.guru\n",
    "    - Alias Records are more capable and hence to be chosen if given an option b/w CNames and Alias Records\n",
    "    - Route 53 recognizes changes in record sets the alias records refers to\n",
    "- MX records, PTR records are also relatively common DNS jargon\n",
    "            \n",
    "- Remember that ELBs do not have a pre-defined IP address, you resolve them using a DNS name\n",
    "- DNS Zone is the part of a domain for which an individual DNS server is responsible\n",
    "- SOA (Start of Authority) record is information stored in a DNS zone about that zone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route 53\n",
    "- Important to know the different routing policies \n",
    "    - Simple: Can only create one record but that record can have mapping to multiple IPs and it allots each request randomly \n",
    "    - Weighted: Can allot some 30% traffic to one AZ, 20% traffic to another AZ and the rest somewhere else.\n",
    "    - Latency: Route requests to server with minimal latency for user\n",
    "    - Failover: Have to set up healthcheck. There should be Primary and Secondary IPs provided\n",
    "    - Geolocation: Routes requests based on the Geo source of requests. \n",
    "    - Multivalue Answer: Kind of like Simple routing but can have different A records pointing to different IP addresses. Can have 12 IP addresses and upto 8 health checks and it will \n",
    "\n",
    "#### Read more\n",
    "- https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/ResourceRecordTypes.html#MXFormat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases\n",
    "#### Relational\n",
    "- SQL Server\n",
    "- Oracla\n",
    "- MySQL\n",
    "- PostgreSQL\n",
    "- Aurora\n",
    "- MariaDB\n",
    "#### Non-relational\n",
    "Has Collection (Table), Document (Row), Key-Value pairs (Fields)\n",
    "#### OLAP (Online Analytics processing)\n",
    "- RedShift\n",
    "#### Elasticache\n",
    "- In memory caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDS\n",
    "- Primarily for OLTP (Online Transaction processing)\n",
    "#### Back ups\n",
    "    - Automated Backups: Taken daily within a retention period. Also saves transaction logs. So, if restoration is necessary, it can take the latest snapshot and play transaction logs to restore it to any second necessary. Also you get free storage on S3 (for backups) that equals the size of your RDS instance. These are deleted if DB is deleted\n",
    "    - DB snapshots: These are user initiated. They are retained even if the DB itself is deleted.\n",
    "- Remember that when a DB is restored, the DNS changes\n",
    "- Once a DB is encrypted, all copies, replicas, snapshots of that DB will be automatically encrypted\n",
    "- At present, encrypting an existing DB is not supported. In order to do that, take a snapshot and encrypt the snapshot\n",
    "- Multi-AZ: AWS maintains an exact replica in different AZs and switches over to the backups when there is a planned maintenance, DB instance failure or AZ failure. **Remember this is for disaster recovery and does not increase performance**. Multi-AZ is enabled by default for Aurora and has to be manually enabled for others\n",
    "- Read Replicas: These are used for performance improvement from an RDS. These are read-only copies of your production DB. Can be in same AZ, diffenet AZ or even different Region\n",
    "    - Can enable encryption\n",
    "    - Must have auto backup enabled\n",
    "    - Can have upto 5 read replicas for a DB\n",
    "    - Can have read replicas of read replicas\n",
    "    - Each read replica has its own DNS\n",
    "    - Each read replica can have Multi-AZ enabled\n",
    "    - Can create read replicas of Multi-AZ source DBs\n",
    "    - Read replicas can be promoted to be their own DB. This stops it from being a replica anymore\n",
    "    \n",
    "    \n",
    "#### Read more on FAQs on RDS\n",
    "- Microsoft SQL Server default max size is 16TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DynamoDB\n",
    "- Fast, flexible NoSQL with consistent, single-digit millisecond latency at scale. \n",
    "- Fully managed DB and supports both document and key-value data models.\n",
    "- Stored on SSD\n",
    "- Spread across 3 geographically distinct data centers\n",
    "- Two read consistency levels\n",
    "    - Eventual consistency: Consistency is usually reached within a second (best read performance)\n",
    "    - Strongly consistent read: returns results that reflects all writes that received a successful response prior to the read\n",
    "- Pricing\n",
    "    - Write throughput \\$0.0065 per hour for every 10 units\n",
    "    - Read throughtput \\$0.0065 per hour for every 50 units\n",
    "    - storage costs of \\$0.25Gb per month\n",
    "    - One DynamoDB read/write capacity unit can handle 1 read/write per second respectively\n",
    "    - Scaling on DynamoDB is just a matter of provisioning more read/write capacity that can be done when the Table is up and running!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redshift\n",
    "- Fast, powerful, fully managed, petabyte-scale data warehouse service in the cloud. \n",
    "- Columnar data storage and is great for OLAP\n",
    "- Advanced Compression techniques as columns are stored together\n",
    "- Massively Parallel Processing (MPP)\n",
    "- Customers can start small for just \\$0.25 and no commitments and scale up to \\$1,000 per TB per year\n",
    "- Has 2 configurations\n",
    "    - Single node (160 GB)\n",
    "    - Multi-Node: Has a **leader node** to manage client connections and **compute nodes** to store data and perform computations (upto 128 Compute nodes)\n",
    "- Pricing\n",
    "    - Compute node hours (billed for 1 unit per node per hour) Not charged for leader node hours\n",
    "    - Charged for backups\n",
    "    - Charged for data transfer (within VPC)\n",
    "- Encryption\n",
    "    - Encrypted in transit using SSL\n",
    "    - Encrypted at rest using AES-256 encryption\n",
    "    - By default RedShift manages keys, but user can also manage it\n",
    "- Availability\n",
    "    - Currently on available in 1 AZ at a time\n",
    "    - Can restore snapshots to new AZ if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticache\n",
    "- Web service to deploy, operate and scale an in-memory cache in the cloud\n",
    "- Two types on AWS\n",
    "    - Memcached\n",
    "    - Redis: Has multi-AZ capability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aurora\n",
    "- MySQL compatible\n",
    "- Five times better perf than MySQL and 1/10th the cost of a commercial DB for comparable perf\n",
    "- Starts with 10 GB and scales in 10GB increments upto 64TB\n",
    "- Compute resources can scale upto 32vCPUs and 244 GBs of Memory\n",
    "- 2 copies of your data is contained in each AZs with a min of 3 AZs. So, 6 copies are maintained\n",
    "- Aurora is designed to handle loss of upto 2 copies of data w/o affecting write and upto 3 copies w/o affecting read availability\n",
    "- Storage is self-healing\n",
    "- 2 Replica types\n",
    "    - Aurora Replica (upto 15)- for failover, these can take over automatically\n",
    "    - MySQL read replica (upto 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VPC\n",
    "- Only one internet gateway allowed per VPC\n",
    "- 1 subnet is always within 1 AZ\n",
    "- Consists of IGW or VPGs, Route tables, Network Access Control lists, Subnets and SGs\n",
    "- Security Groups are Stateful (the inbound connection on a port & protocol will also be allowed to have a response - outbound traffic)\n",
    "- Network Access Control Lists are stateless (inboud and outbound traffic is to be explicitly permitted)\n",
    "- VPC peering does not allow transitive connections (A<->B and B<->C does not imply A<->C)\n",
    "- When a new VPC is created these are auto-generated - SG, NAC, Route table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subnets\n",
    "- 5 ip address fewer than provisioned. The 1st 4  and last addresses of a CIDR block are reserved by Amazon. 1st one is network address and last one is broadcast address. The other three are reserved by Amazon\n",
    "\n",
    "#### NAT Instances (depricated)\n",
    "- Used for servers in a private subnet, there is no internet connection.\n",
    "- NAT instances must be in a public subnet\n",
    "- NAT instances are EC2 machines that work as a gateway to internet\n",
    "- Find AMIs for NAT instances on 3rd party AMIs\n",
    "- Disable source/destination checks on NAT instances\n",
    "- Private subnet should have a route to NAT instance for it to be able to access internet\n",
    "\n",
    "#### NAT Gateway\n",
    "- Can be provisioned from VPC options. Needs the entry \n",
    "- Resides within an AZ\n",
    "- Scale automatically upto 10Gbps\n",
    "- Not associated with an SG\n",
    "- More secure than NAT Instances\n",
    "- No SSH access to NAT Gateway\n",
    "\n",
    "#### NAC Lists (Network Access Control) or Network ACL\n",
    "- One subnet can only be linked to one NAC list\n",
    "- All VPCs come with a default NACL that allows all inbound and outbound traffic\n",
    "- By default, if one creates a private NACL, all inbound and outbound traffic is denied\n",
    "- NACLs are **stateless**\n",
    "- Can block IP addresses using NACLs and not Security Groups\n",
    "\n",
    "**Application Load Balancer should be attached to at least 2 Public Subnets**\n",
    "\n",
    "#### VPC Flow logs\n",
    "- Cannot enable VPC logging for VPC peers unless the VPC is owned by the same a/c\n",
    "- Cannot create tags for flow logs\n",
    "- Cannot change configuration once flow logs are created\n",
    "- Requests to internal AWS addresses are not logged\n",
    "\n",
    "#### NAT vs Bastion \n",
    "- Bastion lets you SSH into a private server for administration\n",
    "\n",
    "### Read on\n",
    "- ENI vs Gateway\n",
    "- Egress only IG allows IPv6 connection initiated by resources within the VPC\n",
    "- Check about default inboud and outbound traffic for newly created SG?\n",
    "- VPC Flow Logs can be created at the VPC, subnet, and network interface levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQS (Simple Queuing Service)\n",
    "- Distribute message queueing system\n",
    "- 256 kB simple text data of any format\n",
    "- Pull based system\n",
    "- Messages can be kept in queue from 1 min to 14 days (default is 4 days)\n",
    "- Long polling is a feature of SQS that allows to notify servers when there is a new message to be processed. This helps to not have the server regularly (short polling) polling SQS looking for messages.\n",
    "- Retains messages (invisible) for 30 seconds by default after it has been delivered. This is for cases when the processing fails.\n",
    "    - If process takes longer than 30 secs, increase visibility timeout. Can increase upto 12 hrs.\n",
    "    - If the process fails, the message can come visible again so that another worker can pick it up\n",
    "- Two types\n",
    "    - Simple queues: Guarantees that messages are delivered at least once but does not guarantee order\n",
    "    - FIFO queues: Guarantees that messages are delivered and also guarantees order. Has a limit of 300 transactions. eg: Bank transactions\n",
    "\n",
    "## SWF (Simple Workflow Service)\n",
    "- Three kind of actors - Workflow starter, Deciders, Activity workers\n",
    "- Ensures that each message is only going to be processed once\n",
    "- It is defined by 'domain'\n",
    "- Parameters are specifided in JSON\n",
    "- Can incorporate human workers too\n",
    "- Functions in a worker - decider fashion\n",
    "\n",
    "## Simple Notification Service (SNS)\n",
    "- Push system\n",
    "- Publish-subscribe\n",
    "- Data type is JSON\n",
    "- Used to send messages triggered from AWS (HTTP, HTTPS, Email, Email-JSON, SQS, Application, Lambda)\n",
    "- 'Topic' are access points for users to subscribe to identical messages across multiple messaging services\n",
    "- Pricing \n",
    "    - Users pay \\$0.5 per 1 million Amazon SNS requests\n",
    "    - \\$0.06 per 100,000 Notification deliveries over HTTP\n",
    "    - \\$0.75 for 100 messages (SMS)\n",
    "    - \\$2 for 100k notifications over email \n",
    "    \n",
    "## Elastic Transcoder\n",
    "- Converts media (video?) content from one to another format\n",
    "- Pricing is based on number of minutes transcoded and the resolution\n",
    "\n",
    "## API Gateway\n",
    "- Also has a feature called API Caching (has an associated TTL)\n",
    "- Low cost & Efficient\n",
    "- Scales effortlessly but have an option to Throttle the gateway to prevent attacks\n",
    "- Can log results to CloudWatch\n",
    "- CORS (Cross Origin Resource Sharing): usually browsers only allow content to be read from the same origin for everything in a page - a security feature. CORS relaxes this constraint. *Origin policy cannot be read at the remote resource* is an error from not having set-up CORS\n",
    "    \n",
    "## Kinesis\n",
    "- Used to handle streaming data\n",
    "- Three services \n",
    "    - Streams: Puts data into Shards\n",
    "        - Retain data from 24 hours to 7 days\n",
    "        - Capacity of stream is the sum of the capacity of its shards\n",
    "        - 5 transactions per second for reads, up to max total data read rate of 2 MB per sec and up to 1000 recs per sec for writes, upto a max write rate of 1 MB per sec. \n",
    "    - Firehose: Don't have to deal with shards. Can use analytics while data is in Firehose and then write to S3\n",
    "    - Analytics: Enables you to run SQL queries on data within streams\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
